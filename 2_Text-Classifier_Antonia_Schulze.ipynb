{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did the loading of the data with glob in the first place, but this was more inconvenient than the load_files like this:\n",
    "\n",
    "Code used with **glob**-module:\n",
    "#get data file names\n",
    "path = (\n",
    "    r\"/Users/antoniaschulze/Desktop/03 Movie/aclImdb/test/pos/\"\n",
    ")\n",
    "filenames = glob.glob(path + \"/*.txt\")\n",
    "\n",
    "test_file = []\n",
    "for filename in filenames:\n",
    "    with open(filename) as file_object:\n",
    "        lines = file_object.readlines()\n",
    "        test_file.append(pd.DataFrame((lines)))\n",
    "\n",
    "#Concatenate all data into one DataFrame\n",
    "test = pd.concat(test_file, ignore_index=True)\n",
    "\n",
    "\n",
    "Loading the files in a kind of \"folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\n",
    "    \"/Users/antoniaschulze/Desktop/03 Movie/aclImdb/train/\",\n",
    "    encoding=\"utf8\",  # specifies the encoding\n",
    "    categories=[\"pos\", \"neg\"],  # identified as target variable\n",
    ")\n",
    "reviews_test = load_files(\n",
    "    \"/Users/antoniaschulze/Desktop/03 Movie/aclImdb/test/\",\n",
    "    encoding=\"utf8\",\n",
    "    categories=[\"pos\", \"neg\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the files in a dataframe and assigning data and target to the columns review and sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15777</th>\n",
       "      <td>what kind of sh*t is this? Power rangers vs Fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>This was one of the most boring movies I've ev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13938</th>\n",
       "      <td>Reviewed at the World Premiere screening Sept....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21617</th>\n",
       "      <td>i'm not sure if it is available worldwide - bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>I've read some terrible things about this film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11287</th>\n",
       "      <td>This is a bad, bad movie. I'm an actual fencer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20252</th>\n",
       "      <td>Obviously a film that has had great influence ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19858</th>\n",
       "      <td>This movie was the beatliest mormon movie made...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11377</th>\n",
       "      <td>One of my favorite movies to date starts as an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17301</th>\n",
       "      <td>I sat down to watch this movie with my friends...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "15777  what kind of sh*t is this? Power rangers vs Fr...          0\n",
       "4837   This was one of the most boring movies I've ev...          0\n",
       "13938  Reviewed at the World Premiere screening Sept....          1\n",
       "21617  i'm not sure if it is available worldwide - bu...          1\n",
       "3329   I've read some terrible things about this film...          1\n",
       "11287  This is a bad, bad movie. I'm an actual fencer...          0\n",
       "20252  Obviously a film that has had great influence ...          1\n",
       "19858  This movie was the beatliest mormon movie made...          0\n",
       "11377  One of my favorite movies to date starts as an...          1\n",
       "17301  I sat down to watch this movie with my friends...          0"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(reviews_train.data, columns=[\"review\"])\n",
    "train[\"sentiment\"] = reviews_train.target\n",
    "train.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23482</th>\n",
       "      <td>LE CERCLE ROUGE is a very good film, though it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>Like a lot of the comments above me, also I th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9250</th>\n",
       "      <td>With Pep Squad receiving an average of 4.7 on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20121</th>\n",
       "      <td>(Contains really bad Spoilers) So what can I s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9926</th>\n",
       "      <td>A woman and her aunt go to Scotland to locate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>Abysmal Indonesian action film from legendary ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14310</th>\n",
       "      <td>If you've never experienced the thing that is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20037</th>\n",
       "      <td>Fantastic movie! One of the best film noir mov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11529</th>\n",
       "      <td>Maybe our standards for Vientam movies have in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19644</th>\n",
       "      <td>Maybe it's just that it was made in 1997, or m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "23482  LE CERCLE ROUGE is a very good film, though it...          1\n",
       "9883   Like a lot of the comments above me, also I th...          0\n",
       "9250   With Pep Squad receiving an average of 4.7 on ...          0\n",
       "20121  (Contains really bad Spoilers) So what can I s...          0\n",
       "9926   A woman and her aunt go to Scotland to locate ...          1\n",
       "23996  Abysmal Indonesian action film from legendary ...          0\n",
       "14310  If you've never experienced the thing that is ...          1\n",
       "20037  Fantastic movie! One of the best film noir mov...          1\n",
       "11529  Maybe our standards for Vientam movies have in...          0\n",
       "19644  Maybe it's just that it was made in 1997, or m...          0"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(reviews_test.data, columns=[\"review\"])\n",
    "test[\"sentiment\"] = reviews_test.target\n",
    "test.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check one specific review in order to get to know what we have to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Horrendous pillaging of a classic.<br /><br />It wasn't written convincingly at all why Mary should develop such sympathy for Bates. He may be more stable until they start playing pranks with him, but he still doesn't help himself at all with his actions. (inviting a comparative stranger to stay alone with him in his until recently disused motel; telling the attractive young girl of his past mental issues; lying about the knives, etc... ) This, in addition to her previous knowledge should have kept Mary extremely wary of him, but this somehow doesn't happen just so they can play the 'mistaken-identity-murder-game later on. Which in itself is also ridiculous: 'So-and-so is the real killer - plus her as well - also him! There were too many contrived twists in order to slap a story on screen when the narrative didn't need extending.<br /><br />It was good to see Perkins reprising his famous role again, but that's about the only small pleasure to be had. It's definitely not a patch on Hitchcock, and if you have no intention of even trying to get close then you shouldn't be bothering at all.\""
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored_example = train[\"review\"][24972]\n",
    "stored_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can identify punctuation, spelling mistakes and much more which we will handle in the following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the text \n",
    "In order to achieve the highest model performance one should feed the regression model with high quality data. In terms of classifying text this implies to run several steps before building the model:\n",
    "\n",
    "a.) make lower case to avoid having different cases for the same words. Having several cases for the same word lowers the model performance as it is not able to combine or at least detect a familarity between \"MoVIe\" and \"moviE\" for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero day leads you to think, even re-think why...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>words can't describe how bad this movie is. i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everyone plays their part pretty well in this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are a lot of highly talented filmmakers/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've just had the evidence that confirmed my s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the movie was sub-par, but this television pil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>this movie has a special way of telling the st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the single worst film i've ever seen in a thea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the plot of this terrible film is so convolute...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i had no idea that mr. izzard was so damn funn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>probably the worst dolph film ever. there's no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the germans all stand out in the open and get ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>considering that i felt like picking up a new ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>barbra streisand's debut television special is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>imagine a woman alone in a house for forty fiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"show people\" is an absolutely delightful sile...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ok, at the beginning it looked like \"shrek\" - ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>there are two distinct ways to enjoy this snap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kurosawa is a proved humanitarian. this movie ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>what a lovely heart warming television movie. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  sentiment\n",
       "0   zero day leads you to think, even re-think why...          1\n",
       "1   words can't describe how bad this movie is. i ...          0\n",
       "2   everyone plays their part pretty well in this ...          1\n",
       "3   there are a lot of highly talented filmmakers/...          0\n",
       "4   i've just had the evidence that confirmed my s...          0\n",
       "5   the movie was sub-par, but this television pil...          1\n",
       "6   this movie has a special way of telling the st...          1\n",
       "7   the single worst film i've ever seen in a thea...          0\n",
       "8   the plot of this terrible film is so convolute...          0\n",
       "9   i had no idea that mr. izzard was so damn funn...          1\n",
       "10  probably the worst dolph film ever. there's no...          0\n",
       "11  the germans all stand out in the open and get ...          0\n",
       "12  considering that i felt like picking up a new ...          0\n",
       "13  barbra streisand's debut television special is...          1\n",
       "14  imagine a woman alone in a house for forty fiv...          0\n",
       "15  \"show people\" is an absolutely delightful sile...          1\n",
       "16  ok, at the beginning it looked like \"shrek\" - ...          1\n",
       "17  there are two distinct ways to enjoy this snap...          1\n",
       "18  kurosawa is a proved humanitarian. this movie ...          1\n",
       "19  what a lovely heart warming television movie. ...          1"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to every row in review the lower function\n",
    "train['review'] = train['review'].apply(lambda x: x.lower())\n",
    "# lambda function joins the lower case words for every review\n",
    "# Split every word with a whitespace make it lower and join it to the new review\n",
    "# train['review'] = train['review'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "test['review'] = test['review'].apply(lambda x: x.lower())\n",
    "train.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.) Remove punctuation as this information is not value-adding in terms of sentiment analysis\n",
    "\n",
    "Having in mind our example above we should replace the punctuation with a white space - otherwise we cant capture \"-\" words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero day leads you to think  even re think why...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>words can t describe how bad this movie is  i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everyone plays their part pretty well in this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are a lot of highly talented filmmakers ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i ve just had the evidence that confirmed my s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  zero day leads you to think  even re think why...          1\n",
       "1  words can t describe how bad this movie is  i ...          0\n",
       "2  everyone plays their part pretty well in this ...          1\n",
       "3  there are a lot of highly talented filmmakers ...          0\n",
       "4  i ve just had the evidence that confirmed my s...          0"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda function is replacing (better said deletes) every punctuation with a whitespace\n",
    "# as we found words-linked-by- and they would be \"joined\" so we rather replace punctuation\n",
    "# with a whitespace\n",
    "train[\"review\"] = train[\"review\"].str.replace(r\"[^\\w\\s]\", \" \")\n",
    "test[\"review\"] = test[\"review\"].str.replace(r\"[^\\w\\s]\", \" \")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.) Delete english stopwords\n",
    "\n",
    "Stopwords are English words which does not add much meaning to a sentence and therefore can be dropped in case of sentiment analysis / NLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero day leads think even think two boys young...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>words describe bad movie explain writing see g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everyone plays part pretty well little nice mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lot highly talented filmmakers actors germany ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evidence confirmed suspicions bunch kids 14 22...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  zero day leads think even think two boys young...          1\n",
       "1  words describe bad movie explain writing see g...          0\n",
       "2  everyone plays part pretty well little nice mo...          1\n",
       "3  lot highly talented filmmakers actors germany ...          0\n",
       "4  evidence confirmed suspicions bunch kids 14 22...          0"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "# if the word x in a review is not in stop(words) join it to the new review-text\n",
    "train['review'] = train['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "test['review'] = test['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the beginning we had this <'br /><br /'> in the review column: \n",
    "before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Horrendous pillaging of a classic.<br /><br />It wasn't written convincingly at all why Mary should develop such sympathy for Bates. He may be more stable until they start playing pranks with him, but he still doesn't help himself at all with his actions. (inviting a comparative stranger to stay alone with him in his until recently disused motel; telling the attractive young girl of his past mental issues; lying about the knives, etc... ) This, in addition to her previous knowledge should have kept Mary extremely wary of him, but this somehow doesn't happen just so they can play the 'mistaken-identity-murder-game later on. Which in itself is also ridiculous: 'So-and-so is the real killer - plus her as well - also him! There were too many contrived twists in order to slap a story on screen when the narrative didn't need extending.<br /><br />It was good to see Perkins reprising his famous role again, but that's about the only small pleasure to be had. It's definitely not a patch on Hitchcock, and if you have no intention of even trying to get close then you shouldn't be bothering at all.\""
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is removed the punctuation but still has \"br\". But this word will be deleted anyways in the next step. So no need to worry right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horrendous pillaging classic br br written convincingly mary develop sympathy bates may stable start playing pranks still help actions inviting comparative stranger stay alone recently disused motel telling attractive young girl past mental issues lying knives etc addition previous knowledge kept mary extremely wary somehow happen play mistaken identity murder game later also ridiculous real killer plus well also many contrived twists order slap story screen narrative need extending br br good see perkins reprising famous role small pleasure definitely patch hitchcock intention even trying get close bothering'"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review'][24972]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.) Common word removal as this might affect model performance\n",
    "\n",
    "Common words don't add any value to the model -> e.g. in this case \"well\" can be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "br       101871\n",
       "movie     44047\n",
       "film      40159\n",
       "one       26795\n",
       "like      20281\n",
       "good      15147\n",
       "time      12727\n",
       "even      12655\n",
       "would     12436\n",
       "story     11988\n",
       "dtype: int64"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a Series that counts the number of occurences of every word and show most occurred 10 values\n",
    "# For all the reviews (not only one review)\n",
    "# by default descending\n",
    "freq_train_top = pd.Series(\" \".join(train[\"review\"]).split()).value_counts()[:10]\n",
    "freq_train_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could argue weather \"great\" should be disregarded here, but in the first place I decided to proceed dropping \"great\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "br       100080\n",
       "movie     43924\n",
       "film      39546\n",
       "one       26808\n",
       "like      19891\n",
       "good      14606\n",
       "time      12383\n",
       "even      12216\n",
       "would     12166\n",
       "see       11550\n",
       "dtype: int64"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_test_top = pd.Series(' '.join(test['review']).split()).value_counts()[:10]\n",
    "freq_test_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the frequency-series to a list and than joins only words to the new review-text if they are not part of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero day leads think think two boys young men ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>words describe bad explain writing see get gri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everyone plays part pretty well little nice be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lot highly talented filmmakers actors germany ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evidence confirmed suspicions bunch kids 14 22...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  zero day leads think think two boys young men ...          1\n",
       "1  words describe bad explain writing see get gri...          0\n",
       "2  everyone plays part pretty well little nice be...          1\n",
       "3  lot highly talented filmmakers actors germany ...          0\n",
       "4  evidence confirmed suspicions bunch kids 14 22...          0"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_train_top = list(freq_train_top.index)\n",
    "train['review'] = train['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_train_top))\n",
    "freq_test_top = list(freq_test_top.index)\n",
    "test['review'] = test['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_test_top))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f.) Lemmatization\n",
    "\n",
    "Word endings with -ly, -ing, -s will be encoded to their \"root\" word and this will increase model performance significantly as it is not having different cases and counts for the same word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textblob\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero day lead think think two boy young men co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word describe bad explain writing see get grip...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everyone play part pretty well little nice bel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lot highly talented filmmaker actor germany no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evidence confirmed suspicion bunch kid 14 22 p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  zero day lead think think two boy young men co...          1\n",
       "1  word describe bad explain writing see get grip...          0\n",
       "2  everyone play part pretty well little nice bel...          1\n",
       "3  lot highly talented filmmaker actor germany no...          0\n",
       "4  evidence confirmed suspicion bunch kid 14 22 p...          0"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review'] = train['review'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "test['review'] = test['review'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g.) Drop words with count < 5\n",
    "\n",
    "If a word is not mentioned more than 5 times in a review, it will not be helpful to predict. So I create another series - with the same structure as freq_train_top which contains the count for every word and then join with lambda function only if the count is greater than 5\n",
    "\n",
    "comment: all of this could have been done in the CountVectorizer itself like e.g. CountVectorizer(min_df = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "character    14183\n",
       "get          12515\n",
       "make         12229\n",
       "see          12016\n",
       "really       11738\n",
       "dtype: int64"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_train = pd.Series(\" \".join(train[\"review\"]).split()).value_counts()\n",
    "freq_test = pd.Series(\" \".join(test[\"review\"]).split()).value_counts()\n",
    "freq_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero day lead think think two boy young men co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word describe bad explain writing see get grip...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>everyone play part pretty well little nice bel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lot highly talented filmmaker actor germany no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evidence confirmed suspicion bunch kid 14 22 p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  zero day lead think think two boy young men co...          1\n",
       "1  word describe bad explain writing see get grip...          0\n",
       "2  everyone play part pretty well little nice bel...          1\n",
       "3  lot highly talented filmmaker actor germany no...          0\n",
       "4  evidence confirmed suspicion bunch kid 14 22 p...          0"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review'] = train['review'].apply(lambda x: \" \".join(x for x in x.split() if freq_train[x] > 5))\n",
    "test['review'] = test['review'].apply(lambda x: \" \".join(x for x in x.split() if freq_test[x] > 5))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h.) Compare review before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Horrendous pillaging of a classic.<br /><br />It wasn't written convincingly at all why Mary should develop such sympathy for Bates. He may be more stable until they start playing pranks with him, but he still doesn't help himself at all with his actions. (inviting a comparative stranger to stay alone with him in his until recently disused motel; telling the attractive young girl of his past mental issues; lying about the knives, etc... ) This, in addition to her previous knowledge should have kept Mary extremely wary of him, but this somehow doesn't happen just so they can play the 'mistaken-identity-murder-game later on. Which in itself is also ridiculous: 'So-and-so is the real killer - plus her as well - also him! There were too many contrived twists in order to slap a story on screen when the narrative didn't need extending.<br /><br />It was good to see Perkins reprising his famous role again, but that's about the only small pleasure to be had. It's definitely not a patch on Hitchcock, and if you have no intention of even trying to get close then you shouldn't be bothering at all.\""
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horrendous classic written convincingly mary develop sympathy bates may stable start playing prank still help action inviting comparative stranger stay alone recently disused motel telling attractive young girl past mental issue lying knife etc addition previous knowledge kept mary extremely wary somehow happen play mistaken identity murder game later also ridiculous real killer plus well also many contrived twist order slap screen narrative need extending see perkins reprising famous role small pleasure definitely patch hitchcock intention trying get close bothering'"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"review\"][24972]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>first got give people got thing together 9 11 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>watched babysitter part eclipse drive cult cla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21790</th>\n",
       "      <td>much potential anyone followed jeffrey know ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14688</th>\n",
       "      <td>actually lie shrek 3 actually first 3d animate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>saw dull waste hbo comedy channel quite innoce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>saw sneak two day official opening must say ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18120</th>\n",
       "      <td>guess fitting tribute first superman crummy pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>big fan musical loved film fred astaire ginger...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8679</th>\n",
       "      <td>actor filmmaker certainly audience among air p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11106</th>\n",
       "      <td>watching many next action star reality tv eps ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "3570   first got give people got thing together 9 11 ...          1\n",
       "2000   watched babysitter part eclipse drive cult cla...          1\n",
       "21790  much potential anyone followed jeffrey know ma...          0\n",
       "14688  actually lie shrek 3 actually first 3d animate...          0\n",
       "9895   saw dull waste hbo comedy channel quite innoce...          0\n",
       "3684   saw sneak two day official opening must say ex...          0\n",
       "18120  guess fitting tribute first superman crummy pa...          0\n",
       "3686   big fan musical loved film fred astaire ginger...          1\n",
       "8679   actor filmmaker certainly audience among air p...          0\n",
       "11106  watching many next action star reality tv eps ...          0"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "declare the different sets needed for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, y_train = test[\"sentiment\"], train[\"sentiment\"]  # target variable\n",
    "X_test, X_train = test[\"review\"], train[\"review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the *Vectorizer* to the train data to get the matrix with one review in a row and the number of count per word. Each word is displayed as a unique column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 23649)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "# load words \"learn vocabulary\"\n",
    "vec.fit(X_train)\n",
    "X_train = vec.transform(X_train)\n",
    "X_train  # vectorized data --> \"bag of words\"\n",
    "X_train.shape  # number of vocabulary (number of columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>00s</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>...</th>\n",
       "      <th>zorak</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zp</th>\n",
       "      <th>zu</th>\n",
       "      <th>zucco</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuckerman</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zuniga</th>\n",
       "      <th>zwick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  23649 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  007  00s  01  02  03  04  05  06  ...    zorak  zorro  zp  zu  \\\n",
       "0   0    0    0    0   0   0   0   0   0   0  ...        0      0   0   0   \n",
       "1   0    0    0    0   0   0   0   0   0   0  ...        0      0   0   0   \n",
       "2   0    0    0    0   0   0   0   0   0   0  ...        0      0   0   0   \n",
       "3   0    0    0    0   0   0   0   0   0   0  ...        0      0   0   0   \n",
       "4   0    0    0    0   0   0   0   0   0   0  ...        0      0   0   0   \n",
       "\n",
       "   zucco  zucker  zuckerman  zulu  zuniga  zwick  \n",
       "0      0       0          0     0       0      0  \n",
       "1      0       0          0     0       0      0  \n",
       "2      0       0          0     0       0      0  \n",
       "3      0       0          0     0       0      0  \n",
       "4      0       0          0     0       0      0  \n",
       "\n",
       "[5 rows x 23649 columns]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train.todense(), columns=vec.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test data\n",
    "X_test = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit bag_of_words to log regression. Evaluation metrics chosen is by default accuracy for **train** data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# declare model as type of Logit Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not sure what you mean by compute the accuracy score but I understood that I should predict it and then compute the accuracy of the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.855"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_scorescore(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both have the same amount of vocabulary as Naive Bayes can only work with words it already knows from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 23649)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 23649)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization\n",
    "Using GridSearchCV to optimize the C hyperparameter of the logistic regression\n",
    "\n",
    "Concatenate the train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proof it worked:  100000\n"
     ]
    }
   ],
   "source": [
    "df = [train, test]\n",
    "dataset = pd.concat(df)\n",
    "print(\"Proof it worked: \", dataset.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Declare different sets again \n",
    "- Apply vectorizer again to the entire dataset bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 27983)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dataset, y_dataset = dataset['review'], dataset['sentiment']\n",
    "vec.fit(X_dataset)  # load words \"learn vocabulary\"\n",
    "X_dataset = vec.transform(X_dataset)\n",
    "X_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining param_grid with the range of C hyperparameters chosen and call the Cross validation search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'C': array([1.000e-04, 1.112e-01, 2.223e-01, 3.334e-01, 4.445e-01, 5.556e-01,\n",
       "       6.667e-01, 7.778e-01, 8.889e-01, 1.000e+00])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"C\": np.linspace(0.0001, 1, num=10)}  # creates a sequence within a and b containing 25 steps\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid=param_grid, cv=10, n_jobs=-1)\n",
    "grid\n",
    "# n_jobs = -1 declares using all cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model with the different C-values for the TRAIN-data\n",
    "\n",
    "Print the different crossvalidation results for different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_dataset, y_dataset)\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the best score achieved with the corresponding best C-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.89198  with  {'C': 0.11120000000000001}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: \", grid.best_score_, \" with \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this grid parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.11120000000000001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87032"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "# use the best C for the original train data and then predict it and compute accuracy for test data\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
